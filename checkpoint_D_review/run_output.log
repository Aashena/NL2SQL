========================================================================
  CHECKPOINT D â€” Generation Pipeline (33 BIRD Dev Questions)
  Provider: gemini  |  Cache: True
========================================================================

Sampled 33 questions:
  QID=64  DB=california_schools  difficulty=simple
  QID=23  DB=california_schools  difficulty=moderate
  QID=28  DB=california_schools  difficulty=challenging
  QID=463  DB=card_games  difficulty=simple
  QID=427  DB=card_games  difficulty=moderate
  QID=431  DB=card_games  difficulty=challenging
  QID=601  DB=codebase_community  difficulty=simple
  QID=571  DB=codebase_community  difficulty=moderate
  QID=586  DB=codebase_community  difficulty=challenging
  QID=1519  DB=debit_card_specializing  difficulty=simple
  QID=1474  DB=debit_card_specializing  difficulty=moderate
  QID=1526  DB=debit_card_specializing  difficulty=challenging
  QID=1027  DB=european_football_2  difficulty=simple
  QID=1025  DB=european_football_2  difficulty=moderate
  QID=1031  DB=european_football_2  difficulty=challenging
  QID=109  DB=financial  difficulty=simple
  QID=135  DB=financial  difficulty=moderate
  QID=149  DB=financial  difficulty=challenging
  QID=953  DB=formula_1  difficulty=simple
  QID=852  DB=formula_1  difficulty=moderate
  QID=994  DB=formula_1  difficulty=challenging
  QID=1349  DB=student_club  difficulty=simple
  QID=1456  DB=student_club  difficulty=moderate
  QID=1464  DB=student_club  difficulty=challenging
  QID=803  DB=superhero  difficulty=simple
  QID=782  DB=superhero  difficulty=moderate
  QID=773  DB=superhero  difficulty=challenging
  QID=1276  DB=thrombosis_prediction  difficulty=simple
  QID=1225  DB=thrombosis_prediction  difficulty=moderate
  QID=1295  DB=thrombosis_prediction  difficulty=challenging
  QID=195  DB=toxicology  difficulty=simple
  QID=237  DB=toxicology  difficulty=moderate
  QID=304  DB=toxicology  difficulty=challenging

Loaded 1534 ground truth SQL statements

Pre-loading artifacts for 11 databases...
  Loading california_schools... done in 7.4s (198,390 LSH entries, 89 FAISS fields)
  Loading card_games... done in 85.6s (563,677 LSH entries, 115 FAISS fields)
  Loading codebase_community... done in 30.5s (326,562 LSH entries, 71 FAISS fields)
  Loading debit_card_specializing... done in 0.0s (1,164 LSH entries, 21 FAISS fields)
  Loading european_football_2... done in 2.0s (96,901 LSH entries, 199 FAISS fields)
  Loading financial... done in 0.2s (9,957 LSH entries, 55 FAISS fields)
  Loading formula_1... done in 45.7s (44,628 LSH entries, 94 FAISS fields)
  Loading student_club... done in 0.4s (21,810 LSH entries, 48 FAISS fields)
  Loading superhero... done in 0.0s (1,526 LSH entries, 31 FAISS fields)
  Loading thrombosis_prediction... done in 0.1s (7,984 LSH entries, 64 FAISS fields)
  Loading toxicology... done in 0.8s (62,916 LSH entries, 11 FAISS fields)
Loading example store... Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
done (9428 entries)

[Q1/33] [california_schools] [simple] What is the total number of schools with a mailing city in Hickman bel...
Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]Loading weights:   1%|          | 1/103 [00:00<00:00, 3013.15it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   1%|          | 1/103 [00:00<00:00, 2563.76it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   2%|â–         | 2/103 [00:00<00:00, 658.96it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   2%|â–         | 2/103 [00:00<00:00, 631.53it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 741.87it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 735.46it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   4%|â–         | 4/103 [00:00<00:00, 958.31it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   4%|â–         | 4/103 [00:00<00:00, 943.60it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   5%|â–         | 5/103 [00:00<00:00, 1061.15it/s, Materializing param=embeddings.word_embeddings.weight]     Loading weights:   5%|â–         | 5/103 [00:00<00:00, 1052.42it/s, Materializing param=embeddings.word_embeddings.weight]Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 1169.63it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 1161.70it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 1321.04it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 1312.13it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 1471.17it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 1463.34it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 1564.97it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 1557.42it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1642.06it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1633.23it/s, Materializing param=encoder.layer.0.attention.self.key.bias]Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1769.61it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1761.44it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1885.29it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1818.14it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1928.55it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1920.00it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1951.23it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1942.51it/s, Materializing param=encoder.layer.0.attention.self.value.bias]Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 1953.69it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 1945.59it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 2037.43it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 2030.22it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 2084.89it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 2072.47it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 2104.58it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 2097.39it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 2194.04it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 2186.69it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 2244.44it/s, Materializing param=encoder.layer.0.output.dense.bias]      Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 2236.13it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 2321.51it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 2314.55it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 2309.47it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 2302.49it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 2246.97it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 2239.35it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 2313.25it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 2306.15it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 2362.30it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 2355.40it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 2387.77it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 2381.36it/s, Materializing param=encoder.layer.1.attention.self.key.bias]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 2432.42it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 2426.32it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 2496.45it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 2490.26it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 2525.22it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 2431.68it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 2497.50it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 2491.52it/s, Materializing param=encoder.layer.1.attention.self.value.bias]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 2560.73it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 2554.59it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 2614.60it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 2608.65it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 2665.36it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 2658.91it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 2686.68it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 2597.80it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 2594.89it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 2589.17it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 2644.53it/s, Materializing param=encoder.layer.1.output.dense.bias]      Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 2639.13it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 2694.63it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 2689.17it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 2746.05it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 2739.91it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 2791.53it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 2785.73it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 2844.95it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 2839.26it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 2898.77it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 2893.21it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 2947.80it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 2942.19it/s, Materializing param=encoder.layer.2.attention.self.key.bias]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 2996.53it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 2990.07it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 3014.08it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 3008.58it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 3052.33it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 3040.77it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 3092.65it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 3086.42it/s, Materializing param=encoder.layer.2.attention.self.value.bias]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 3079.37it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 3073.52it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 3122.55it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 3114.68it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 3160.69it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 3155.02it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 3169.00it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 3163.41it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 3201.52it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 3196.11it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 3211.90it/s, Materializing param=encoder.layer.2.output.dense.bias]      Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 3206.51it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 3251.35it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 3245.94it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 3225.06it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 3219.46it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 3205.50it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 3199.32it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 3231.36it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 3226.17it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 3196.15it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 3190.78it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 3233.55it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 3228.14it/s, Materializing param=encoder.layer.3.attention.self.key.bias]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 3266.72it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 3261.86it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 3306.72it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 3301.78it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 3345.79it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 3340.85it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 3384.84it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 3380.04it/s, Materializing param=encoder.layer.3.attention.self.value.bias]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 3423.92it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 3419.09it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 3450.33it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 3444.57it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 3480.97it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 3475.38it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 3481.58it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 3476.25it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 3511.72it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 3506.59it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 3494.18it/s, Materializing param=encoder.layer.3.output.dense.bias]      Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 3484.66it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 3481.17it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 3476.28it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 3457.67it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 3452.55it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 3432.96it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 3423.02it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 3450.45it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 3445.84it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 3476.17it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 3471.55it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 3477.63it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 3472.57it/s, Materializing param=encoder.layer.4.attention.self.key.bias]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 3499.76it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 3495.18it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 3529.15it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 3524.70it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 3555.43it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 3551.02it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 3587.86it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 3583.23it/s, Materializing param=encoder.layer.4.attention.self.value.bias]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 3620.05it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 3614.40it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 3651.83it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 3647.50it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 3685.32it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 3681.17it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 3716.47it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 3712.29it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 3749.39it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 3745.16it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 3781.41it/s, Materializing param=encoder.layer.4.output.dense.bias]      Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 3777.36it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 3813.04it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 3808.77it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 3845.97it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 3841.67it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 3875.45it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 3871.17it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 3907.63it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 3903.29it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 3939.10it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 3934.91it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 3971.04it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 3966.87it/s, Materializing param=encoder.layer.5.attention.self.key.bias]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 4002.45it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 3998.26it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 4033.49it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 4029.07it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 4061.50it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 4057.06it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 4088.35it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 4083.95it/s, Materializing param=encoder.layer.5.attention.self.value.bias]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 4119.16it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 4114.70it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 4149.22it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 4144.74it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 4179.78it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 4175.49it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 4210.54it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 4206.19it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 4241.08it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 4236.71it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 4271.53it/s, Materializing param=encoder.layer.5.output.dense.bias]     Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 4267.32it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 4301.94it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 4297.70it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 4332.34it/s, Materializing param=pooler.dense.bias]                  Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 4328.09it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 4360.16it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 4355.94it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 4344.72it/s, Materializing param=pooler.dense.weight]
[1mBertModel LOAD REPORT[0m from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
Schema linker S2 LLM call failed (Gemini candidate has no content (finish_reason=MALFORMED_FUNCTION_CALL)); using S1 as S2 fallback.
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
Grounding LLM error for question 'For the customer who paid 634.8 in 2012/8/25, what was the c' â€” falling back to keyword extraction (15 tokens extracted): Gemini candidate has no content (finish_reason=MALFORMED_FUNCTION_CALL)
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
ICLGenerator icl_C2: response truncated at MAX_TOKENS (partial text discarded)
ICLGenerator icl_C3: response truncated at MAX_TOKENS (partial text discarded)
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=4096); retrying with max_tokens=8192
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=4096); retrying with max_tokens=8192
Schema linker S2 LLM call failed (Gemini candidate has no content (finish_reason=MALFORMED_FUNCTION_CALL)); using S1 as S2 fallback.
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
ICLGenerator icl_C1: response truncated at MAX_TOKENS (partial text discarded)
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=4096); retrying with max_tokens=8192
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=4096); retrying with max_tokens=8192
ICLGenerator icl_C3: response truncated at MAX_TOKENS (partial text discarded)
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
Gemini response has no text or tool output: finish_reason=FinishReason.MAX_TOKENS, safety_ratings=None, parts(thought,has_text)=[]
MAX_TOKENS hit with no output (max_tokens=2000); retrying with max_tokens=4000
Schema linker S2 LLM call failed (Gemini candidate has no content (finish_reason=MALFORMED_FUNCTION_CALL)); using S1 as S2 fallback.
  [Op5] cells=7, hints=['schools', 'mailing city', 'charter number'], few_shot=8
  [Op6] S1=3 fields, S2=5 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=11, unique_sql=3, ORACLE=YES

[Q2/33] [california_schools] [moderate] List the names of schools with more than 30 difference in enrollements...
  [Op5] cells=1, hints=['names of schools', 'full street adress', 'Enrollment (K-12)', 'Enrollment (Ages 5-17)'], few_shot=8
  [Op6] S1=7 fields, S2=13 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=10, unique_sql=7, ORACLE=YES

[Q3/33] [california_schools] [challenging] Consider the average difference between K-12 enrollment and 15-17 enro...
  [Op5] cells=10, hints=['Enrollment (K-12)', 'Enrollment (Ages 5-17)', 'names', 'DOC type', 'schools'], few_shot=8
  [Op6] S1=7 fields, S2=12 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=0, unique_sql=10, ORACLE=NO

[Q4/33] [card_games] [simple] How many translations are there for the set of cards with "Angel of Me...
  [Op5] cells=3, hints=['translations', 'name'], few_shot=8
  [Op6] S1=6 fields, S2=9 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=0, unique_sql=7, ORACLE=NO

[Q5/33] [card_games] [moderate] What languages are available in the set known as Archenemy on the magi...
  [Op5] cells=9, hints=['mcmName', 'setCode', 'languages'], few_shot=8
  [Op6] S1=6 fields, S2=14 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=10, unique_sql=7, ORACLE=YES

[Q6/33] [card_games] [challenging] Which set is not available outside of the United States and has foil c...
  [Op5] cells=10, hints=['isForeignOnly', 'isFoilOnly', 'language', 'set ID'], few_shot=8
  [Op6] S1=8 fields, S2=8 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=1, unique_sql=6, ORACLE=YES

[Q7/33] [codebase_community] [simple] What is the score and the link type ID for post ID 395?...
  [Op5] cells=4, hints=['score', 'link type ID', 'post ID'], few_shot=8
  [Op6] S1=9 fields, S2=17 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=11, unique_sql=3, ORACLE=YES

[Q8/33] [codebase_community] [moderate] For the user No.24, how many times is the number of his/her posts comp...
  [Op5] cells=1, hints=['post.Id', 'votes.Id', 'UserId', 'OwnerUserId'], few_shot=8
  [Op6] S1=7 fields, S2=12 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=0, unique_sql=8, ORACLE=NO

[Q9/33] [codebase_community] [challenging] Which user added a bounty amount of 50 to the post title mentioning va...
  [Op5] cells=4, hints=['BountyAmount', 'DisplayName', 'Title'], few_shot=8
  [Op6] S1=12 fields, S2=18 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=0, unique_sql=5, ORACLE=NO

[Q10/33] [debit_card_specializing] [simple] What was the product id of the transaction happened at 2012/8/23 21:20...
  [Op5] cells=3, hints=['product id', 'date', 'T1.time'], few_shot=8
  [Op6] S1=4 fields, S2=7 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=11, unique_sql=1, ORACLE=YES

[Q11/33] [debit_card_specializing] [moderate] Which customers, paying in CZK, consumed the most gas in 2011?...
  [Op5] cells=2, hints=['customers', 'gas', 'paying', 'consumed'], few_shot=8
  [Op6] S1=5 fields, S2=12 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=10, unique_sql=6, ORACLE=YES

[Q12/33] [debit_card_specializing] [challenging] For the customer who paid 634.8 in 2012/8/25, what was the consumption...
  [Op5] cells=2, hints=[], few_shot=8
  [Op6] S1=7 fields, S2=10 fields
  [Op7] 11 candidates, exec_ok=6, oracle_match=6, unique_sql=9, ORACLE=YES

[Q13/33] [european_football_2] [simple] Indicate the full names of the top 10 players with the highest number ...
  [Op5] cells=0, hints=['player_name', 'penalties'], few_shot=8
  [Op6] S1=6 fields, S2=16 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=0, unique_sql=6, ORACLE=NO

[Q14/33] [european_football_2] [moderate] Give the name of the league had the most goals in the 2016 season?...
  [Op5] cells=1, hints=['home_team_goal', 'away_team_goal', 'season'], few_shot=8
  [Op6] S1=20 fields, S2=25 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=11, unique_sql=5, ORACLE=YES

[Q15/33] [european_football_2] [challenging] At present, calculate for the player's age who have a sprint speed of ...
  [Op5] cells=3, hints=['birthday', 'sprint_speed', 'date'], few_shot=8
  [Op6] S1=7 fields, S2=7 fields
  [Op7] 11 candidates, exec_ok=8, oracle_match=1, unique_sql=10, ORACLE=YES

[Q16/33] [financial] [simple] How many clients opened their accounts in Jesenik branch were women?...
  [Op5] cells=2, hints=['gender', 'A2'], few_shot=8
  [Op6] S1=10 fields, S2=10 fields
  [Op7] 11 candidates, exec_ok=10, oracle_match=1, unique_sql=10, ORACLE=YES

[Q17/33] [financial] [moderate] After making a credit card withdrawal, how many account/s with monthly...
  [Op5] cells=7, hints=['Operation', 'Frequency', 'balance', 'account'], few_shot=8
  [Op6] S1=7 fields, S2=9 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=2, unique_sql=4, ORACLE=YES

[Q18/33] [financial] [challenging] Please list the account types that are not eligible for loans, and the...
  [Op5] cells=1, hints=['account type', 'A11'], few_shot=8
  [Op6] S1=8 fields, S2=8 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=1, unique_sql=5, ORACLE=YES

[Q19/33] [formula_1] [simple] How many French constructors have a lap number of over 50?...
  [Op5] cells=3, hints=['constructors', 'laps'], few_shot=8
  [Op6] S1=8 fields, S2=15 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=8, unique_sql=4, ORACLE=YES

[Q20/33] [formula_1] [moderate] How many races in the year 2010 are held on grand prixs outside Asia a...
  [Op5] cells=3, hints=['races', 'grand prixs'], few_shot=8
  [Op6] S1=5 fields, S2=8 fields
  [Op7] 11 candidates, exec_ok=10, oracle_match=3, unique_sql=9, ORACLE=YES

[Q21/33] [formula_1] [challenging] Which constructor scored most points from Monaco Grand Prix between 19...
  [Op5] cells=9, hints=['constructor', 'points', 'score', 'name', 'nationality', 'team', 'race', 'year'], few_shot=8
  [Op6] S1=11 fields, S2=21 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=10, unique_sql=11, ORACLE=YES

[Q22/33] [student_club] [simple] Provide the total number of the budget amount for "September Speaker" ...
  [Op5] cells=4, hints=['amount'], few_shot=8
  [Op6] S1=5 fields, S2=7 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=11, unique_sql=1, ORACLE=YES

[Q23/33] [student_club] [moderate] List the full name of the top five members who spend the most money in...
  [Op5] cells=0, hints=['first_name', 'last_name', 'expense', 'cost'], few_shot=8
  [Op6] S1=9 fields, S2=15 fields
  [Op7] 11 candidates, exec_ok=10, oracle_match=0, unique_sql=5, ORACLE=NO

[Q24/33] [student_club] [challenging] Write the full names of students who received funds on the date of 9/9...
  [Op5] cells=0, hints=['first_name', 'last_name', 'amount', 'date_received'], few_shot=8
  [Op6] S1=9 fields, S2=14 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=9, unique_sql=4, ORACLE=YES

[Q25/33] [superhero] [simple] What is the power ID of cryokinesis?...
  [Op5] cells=1, hints=['superpower.id', 'power_name'], few_shot=8
  [Op6] S1=2 fields, S2=4 fields
  [Op7] 11 candidates, exec_ok=10, oracle_match=10, unique_sql=2, ORACLE=YES

[Q26/33] [superhero] [moderate] List the heroes' names whose eyes and hair colours are both black....
  [Op5] cells=2, hints=['superhero_name', 'eye_colour_id', 'hair_colour_id', 'colour.colour'], few_shot=8
  [Op6] S1=11 fields, S2=17 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=11, unique_sql=3, ORACLE=YES

[Q27/33] [superhero] [challenging] Which superhero has the same eyes, hair and skin colour? Indicate the ...
  [Op5] cells=0, hints=['superhero_name', 'hair_colour_id', 'skin_colour_id', 'eye_colour_id', 'publisher_name'], few_shot=8
  [Op6] S1=11 fields, S2=14 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=11, unique_sql=4, ORACLE=YES

[Q28/33] [thrombosis_prediction] [simple] For the patients who have an abnormal level of anti-DNA, please list t...
  [Op5] cells=3, hints=['DNA', 'Diagnosis'], few_shot=8
  [Op6] S1=5 fields, S2=8 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=10, unique_sql=5, ORACLE=YES

[Q29/33] [thrombosis_prediction] [moderate] List and group all patients by sex for total bilirubin (T-BIL) level n...
  [Op5] cells=1, hints=['T-BIL', 'sex', 'ID'], few_shot=8
  [Op6] S1=5 fields, S2=6 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=0, unique_sql=9, ORACLE=NO

[Q30/33] [thrombosis_prediction] [challenging] Among the patients whose total bilirubin is over the normal range, how...
  [Op5] cells=2, hints=['T-BIL', 'ANA Pattern'], few_shot=8
  [Op6] S1=5 fields, S2=7 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=1, unique_sql=6, ORACLE=YES

[Q31/33] [toxicology] [simple] What is the most common bond type?...
  [Op5] cells=0, hints=['bond_type'], few_shot=8
  [Op6] S1=3 fields, S2=6 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=11, unique_sql=3, ORACLE=YES

[Q32/33] [toxicology] [moderate] Which molecule does the atom TR001_10 belong to? Please state whether ...
  [Op5] cells=4, hints=['molecule', 'carcinogenic', 'atom id', 'label', 'molecules'], few_shot=8
  [Op6] S1=4 fields, S2=4 fields
  [Op7] 11 candidates, exec_ok=10, oracle_match=0, unique_sql=7, ORACLE=NO

[Q33/33] [toxicology] [challenging] List all carcinogenic molecules and their elements....
  [Op5] cells=1, hints=['label', 'element'], few_shot=8
  [Op6] S1=5 fields, S2=5 fields
  [Op7] 11 candidates, exec_ok=11, oracle_match=1, unique_sql=9, ORACLE=YES

========================================================================
  SUMMARY STATISTICS
========================================================================

Oracle Upper Bound: 25/33 = 75.8%
  simple      : 9/11 = 81.8%
  moderate    : 7/11 = 63.6%
  challenging : 9/11 = 81.8%

Per-Database Oracle:
  california_schools            : 2/3 = 66.7%
  card_games                    : 2/3 = 66.7%
  codebase_community            : 1/3 = 33.3%
  debit_card_specializing       : 3/3 = 100.0%
  european_football_2           : 2/3 = 66.7%
  financial                     : 3/3 = 100.0%
  formula_1                     : 3/3 = 100.0%
  student_club                  : 2/3 = 66.7%
  superhero                     : 3/3 = 100.0%
  thrombosis_prediction         : 2/3 = 66.7%
  toxicology                    : 2/3 = 66.7%

Per-Generator Success Rate:
  Generator             Total  Non-empty  Exec OK   Oracle
  -------------------- ------ ---------- -------- --------
  A_reasoning             132   132 (100%)   131 (99%)    63 (47%)
  B1_standard              66    66 (100%)    63 (95%)    34 (51%)
  B2_complex               66    66 (100%)    62 (93%)    35 (53%)
  C_icl                    99    95 (95%)    94 (94%)    50 (50%)

Candidate Diversity:
  Total non-error candidates: 359
  Unique SQL strings:         198
  Duplicates:                 161 (44%)
  Avg candidates/question:    10.9

Per-Question Results:
   QID  DB                    Diff        Cands  ExecOK   OracleMatch  Error
  ----  --------------------  ----------  -----  ------  ------------  ------------------------------
    64  california_schools    simple         11      11           YES  
    23  california_schools    moderate       11      11           YES  
    28  california_schools    challenging     11      11           NO   
   463  card_games            simple         11      11           NO   
   427  card_games            moderate       11      11           YES  
   431  card_games            challenging     11      11           YES  
   601  codebase_community    simple         11      11           YES  
   571  codebase_community    moderate       11      11           NO   
   586  codebase_community    challenging     11      11           NO   
  1519  debit_card_specializ  simple         11      11           YES  
  1474  debit_card_specializ  moderate       11      11           YES  
  1526  debit_card_specializ  challenging     11       6           YES  
  1027  european_football_2   simple         11      11           NO   
  1025  european_football_2   moderate       11      11           YES  
  1031  european_football_2   challenging     11       8           YES  
   109  financial             simple         11      10           YES  
   135  financial             moderate       11      11           YES  
   149  financial             challenging     11      11           YES  
   953  formula_1             simple         11      11           YES  
   852  formula_1             moderate       11      10           YES  
   994  formula_1             challenging     11      11           YES  
  1349  student_club          simple         11      11           YES  
  1456  student_club          moderate       11      10           NO   
  1464  student_club          challenging     11      11           YES  
   803  superhero             simple         11      10           YES  
   782  superhero             moderate       11      11           YES  
   773  superhero             challenging     11      11           YES  
  1276  thrombosis_predictio  simple         11      11           YES  
  1225  thrombosis_predictio  moderate       11      11           NO   
  1295  thrombosis_predictio  challenging     11      11           YES  
   195  toxicology            simple         11      11           YES  
   237  toxicology            moderate       11      10           NO   
   304  toxicology            challenging     11      11           YES  

Total elapsed: 1884.5s

Detailed results saved to: /Users/mostafa/Documents/workplace/NL2SQL/checkpoint_D_review/results.json
========================================================================
  CHECKPOINT D COMPLETE
========================================================================
