# Checkpoint B — Offline Pipeline Review

**Date**: 2026-02-22
**Provider**: Gemini (gemini-2.5-flash / gemini-2.5-pro)
**Pipeline**: Ops 0a (profile) → 0b (summarize) → 0c (format) → 1 (LSH + FAISS + ExampleStore)

## Files

| File | Description |
|------|-------------|
| `inspection_report.txt` | Full output of inspect_results.py (LSH, FAISS, ExampleStore queries) |
| `inspect_results.py` | Script that generated the report — rerunnable at any time |
| `README.md` | This file |

---

## 1. Pipeline Summary

All **11/11 BIRD dev databases** processed successfully. **0 failures.**

| Database | LSH size | FAISS fields | Notes |
|---|---|---|---|
| california_schools | 1.2 GB | 89 | Large: indexes 268K values |
| card_games | 2.7 GB | 115 | 13 cols skipped (>50K distinct) |
| codebase_community | 2.8 GB | 71 | 15 cols skipped (>50K distinct) |
| debit_card_specializing | 340 MB | 21 | Fast (small DB) |
| european_football_2 | 1.8 GB | 297 | Very wide schema |
| financial | 497 MB | 87 | Normal |
| formula_1 | 698 MB | 143 | Normal |
| student_club | 298 MB | 73 | Small |
| superhero | 20 MB | 76 | Very small (low cardinality) |
| thrombosis_prediction | 88 MB | 95 | Normal |
| toxicology | 284 MB | 11 | Tiny schema |
| **Total LSH** | **10.86 GB** | | Significant disk footprint |

**Example store**: 9,428 training examples, 14.5 MB FAISS, 5.3 MB metadata.

**Total runtime**: ~101 minutes for all 11 databases (wall time).

---

## 2. LSH Index Quality — california_schools

**Query tests** (see `inspection_report.txt` for full output):

| Query | Top result | Result quality |
|---|---|---|
| `"Alameda"` (exact) | `frpm.County Name = 'Alameda'` (sim=1.0) | ✅ Perfect — returns all tables |
| `"Berkley"` (typo for Berkeley) | `schools.MailCity = 'Berkley'` (exact!), then `City = 'Berkeley'` (sim=0.38) | ⚠️ Finds typo as exact match (correct), but sim=0.38 for true target is LOW |
| `"Los Angelos"` (typo for Los Angeles) | `frpm.County Name = 'Los Angeles'` (sim=0.742) | ✅ Good — 3-gram Jaccard handles the swap well |

**Critical finding**: `"Berkley"` → `"Berkeley"` returns similarity 0.38 only (1-char transposition).
This is a known limitation of 3-gram Jaccard: "Berkley" and "Berkeley" share only 2 of 6 trigrams.
The LSH threshold=0.3 catches it, but schema linker may deprioritize it if score threshold is set high.

**Distribution concern**: Top 20 columns are dominated by ID/address/lat-lng columns (CDSCode, NCESSchool, Latitude, Longitude, Phone, Email). These consume 185K/268K entries (69%) and will never be queried meaningfully. See Issue #1 below.

---

## 3. FAISS Semantic Search Quality — california_schools

All queries return highly relevant fields:

| Query | Top match | Score | Assessment |
|---|---|---|---|
| `"county name"` | `frpm.County Name` | 0.573 | ✅ Correct |
| `"free meal count in schools"` | `frpm.FRPM Count (Ages 5-17)` | 0.773 | ✅ Excellent |
| `"school district enrollment"` | `frpm.Enrollment (K-12)` | 0.638 | ✅ Good |
| `"academic performance score"` | `satscores.AvgScrWrite` | 0.572 | ✅ Reasonable |
| `"student eligibility for reduced price lunch"` | `frpm.FRPM Count (Ages 5-17)` | 0.725 | ✅ Good |

The FAISS semantic search is **working very well**. The field summaries generated by Gemini are high quality and semantically meaningful. 0/89 fields got default fallback summaries.

---

## 4. Example Store Quality

9,428 training examples loaded and queryable. Sample retrievals:

| Query | Retrieved examples | Assessment |
|---|---|---|
| `"free meal counts in schools"` | `menu.Dish (lowest_price=0)`, `student_loan` | ⚠️ Structurally OK but semantically weak (free ≠ free meal) |
| `"cards with mana cost > 5"` | works_cycles, sales (cost/price queries) | ✅ Reasonable structural match (comparison+count) |
| `"highest salary"` | `retail_world.Employees`, `human_resources` | ✅ Excellent — directly relevant examples |

The skeleton masking (NUM/STR/ENTITY) is doing a good job. Examples from `retail_world` for salary queries show the structural similarity approach works.

---

## 5. Field Summary Quality

Spot-checked 15 fields from california_schools:
- **0/89 default fallbacks** — all fields got real LLM-generated summaries
- Summaries are concise, accurate, and domain-aware
- Short summaries (10-20 words) are suitable for FAISS embedding
- Long summaries (50-100 words) give rich context for schema linking

---

## 6. Issues Found & Recommendations

### Issue 1 (MEDIUM): LSH indexes useless columns — bloating index 10x

**Problem**: The LSH index includes all columns regardless of type. For california_schools, 69% of 268K indexed entries are from address/phone/email/lat-lng columns that will never be matched via natural-language keyword queries.

**Impact**:
- Total LSH footprint: **10.86 GB** for 11 databases
- Per-DB sizes range from 20 MB to 2.8 GB
- Build time was ~101 minutes, dominated by MinHash computation for these columns
- Query time slightly slower (more candidates to re-rank)

**Fix applied**: ✅ Added `_MAX_DISTINCT_PER_COLUMN = 50_000` cap (same as profiler). This fixed the card_games LSH which was previously running for 48+ minutes without completing. Card_games now completes in 10 minutes.

**Recommended additional fix**: Filter columns by type affinity from profiler — skip `INTEGER` and `REAL` type affinity columns entirely in LSH (they're never fuzzy-matched by text). This would reduce california_schools LSH by ~50%.

### Issue 2 (LOW): Summarizer batch failures on large text columns

**Problem**: card_games/cards had 5 batch failures (batch_size=6), retrying individually each time. The purchaseUrls and text columns have very long distinct values that overflow context when batched.

**Impact**: Extra API calls, ~30s additional latency per batch failure. Correctness maintained.

**Fix**: Already handled by individual retry logic. No urgent action needed. Could reduce batch_size from 6→4 for databases with free-text columns.

### Issue 3 (LOW): SSL "event loop closed" errors in output

**Problem**: After each `asyncio.run(summarize_database(...))` call, a benign `RuntimeError: Event loop is closed` error appears in logs. This is asyncio cleanup noise when `httpx` has a pending write after the event loop is torn down.

**Impact**: None — purely cosmetic. Does not affect correctness.

**Fix**: Could suppress with `asyncio.set_event_loop_policy` or move to persistent async loop across databases. Not worth fixing now.

### Issue 4 (INFO): Typo tolerance is low for 1-char transpositions in short words

**Problem**: "Berkley" (6 chars) → "Berkeley" (8 chars) returns sim=0.38. The 3-gram Jaccard for strings of different lengths with a single transposition is ~0.38-0.47. This is above our threshold of 0.3, so it IS retrieved, but just barely.

**Impact**: Queries with short-word typos (< 7 chars) may not reliably find the correct value. The exact match on "Berkley" (which literally exists in the DB) obscures the issue slightly.

**No fix needed**: The correct value IS retrieved at sim=0.38 which is above threshold=0.3. Schema linker will see multiple candidates and use the LLM to pick the right one.

---

## 7. Proposed Changes Before Prompt 7

Based on the above analysis, here are proposed improvements for you to approve:

| # | Change | Priority | Effort |
|---|---|---|---|
| A | Filter non-TEXT columns from LSH (use profiler type_affinity) | MEDIUM | ~30 min |
| B | Reduce LSH batch count query overhead (count LIMIT before fetching values) | LOW | Already done (part of fix) |
| C | Nothing — proceed to Prompt 7 | — | 0 |

**Recommendation**: Implement change **A** before Prompt 7. It will:
- Reduce LSH footprint by ~50-70% for most databases
- Speed up future re-runs
- Make the index more relevant (only TEXT columns matter for cell-value matching)

If you prefer to proceed without change A, the pipeline is functionally correct and all tests pass.

---

## 8. Decisions Needed

Please decide:

1. **LSH column filtering** (Issue #1): Should we add a TEXT-only filter using profiler type_affinity before Prompt 7?
2. **Summarizer batch size** (Issue #2): Should we reduce batch_size from 6 to 4 for large-text databases?
3. **Proceed to Prompt 7**: After any approved changes, shall we continue with cache_manager + context_grounder?
